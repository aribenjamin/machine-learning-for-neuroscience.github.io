---
title: "Chapter 6"
exports:
  - format: tex
    logo: false
    template: ../templates/plain_latex_book_chapter
    output: exports/chap6.tex
---
<a href="https://www.nature.com/articles/s41467-022-35659-7" class="prominent-link">
  <div class="prominent-link-title">Article link</div>
  <div class="prominent-link-description">Nature Communications</div>
</a>

# Efficient neural codes naturally emerge through gradient descent learning

_Foreword_

This chapter focus on how sensory representations are shaped by learning. In a collaboration with Alan Stockerâ€™s lab , we showed how many aspects of visual perception can be explained with ideas from the study of learning in artificial neural networks. In this chapter, machine learning plays Role 4, a model of the brain.

This chapter links two frameworks in two fields: efficient coding (in sensory neuroscience) and the implicit biases of gradient descent (in deep learning theory). Both create similar sensory representations. This link is surprising, and can explain why artificial neural networks trained on natural image tasks appear in many ways similar to neural responses in the ventral stream (reviewed in Chapter 4, Role 4). 

We do not treat this this result as evidence that the brain performs gradient descent, although is suggestive. Many algorithms might lead to similar outcomes. However, it is a powerful proof of principle of an alternative type of explanation for neuroscience. Sensory representations might be explained by appealing not just to evolution, but to the process of sensory learning in infancy. Whatever algorithm the brain uses to generalize from limited experience, it will shape sensory representations in the adult. 

Deep learning theory has a great deal to offer neuroscience beyond this finding. Future work may help to describe why adults and infants alike learn what they do.
