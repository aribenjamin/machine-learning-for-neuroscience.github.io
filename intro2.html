
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="Learning and its consequences" property="og:title"/>
<meta content="website" property="og:type"/>
<meta content="https://stupendous-churros-2104dd.netlify.app/intro2.html" property="og:url"/>
<meta content="Complex systems can emerge from simple rules. Recently, some in computational neuroscience have argued to shift the focus away from the computations performed in the brain and towards how they are ..." property="og:description"/>
<meta content="https://stupendous-churros-2104dd.netlify.app_images/logo.png" property="og:image"/>
<meta content="Learning and its consequences" property="og:image:alt"/>
<title>Learning and its consequences — Machine Learning as Tool and Theory in Computational Neuroscience</title>
<link href="_static/css/theme.css" rel="stylesheet"/>
<link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet"/>
<link href="_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<!-- add `style` or `link` tags with your CSS `@font-face` declarations here -->
<!-- ... and optionally preload the `woff2` for snappier page loads -->
<link as="font" crossorigin="" href="_static/et-book/et-book-bold-line-figures/et-book-bold-line-figures.woff" rel="preload" type="font/woff"/>
<link as="font" crossorigin="" href="_static/et-book/et-book-display-italic-old-style-figures/et-book-display-italic-old-style-figures.woff" rel="preload" type="font/woff"/>
<link as="font" crossorigin="" href="_static/et-book/et-book-roman-line-figures/et-book-roman-line-figures.woff" rel="preload" type="font/woff"/>
<link as="font" crossorigin="" href="_static/et-book/et-book-roman-old-style-figures/et-book-roman-old-style-figures.woff" rel="preload" type="font/woff"/>
<link as="font" crossorigin="" href="_static/et-book/et-book-semi-bold-old-style-figures/et-book-semi-bold-old-style-figures.woff" rel="preload" type="font/woff"/>
<link href="_static/pygments.css" rel="stylesheet" type="text/css">
<link href="_static/sphinx-book-theme.59e7d1499aa759519747cb2a1a335dc4.css" rel="stylesheet" type="text/css">
<link href="_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="_static/sphinx-thebe.css" rel="stylesheet" type="text/css">
<link href="_static/tufte.css" rel="stylesheet" type="text/css">
<link href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css">
<link href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<link as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js" rel="preload"/>
<script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
<script src="_static/jquery.js"></script>
<script src="_static/underscore.js"></script>
<script src="_static/doctools.js"></script>
<script src="_static/togglebutton.js"></script>
<script src="_static/clipboard.min.js"></script>
<script src="_static/copybutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script src="_static/sphinx-book-theme.90c857b2bf8f3d46aa488b0ed8bf60a6.js"></script>
<script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
<script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
<link href="https://stupendous-churros-2104dd.netlify.app/intro2.html" rel="canonical">
<link href="_static/logo.png" rel="shortcut icon"/>
<link href="genindex.html" rel="index" title="Index"/>
<link href="search.html" rel="search" title="Search"/>
<link href="structure.html" rel="next" title="Structure of this dissertation"/>
<link href="intro1.html" rel="prev" title="Neurophysiology practice and the complexity of sensory cortex"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<meta content="summary" name="twitter:card">
<meta content="@patrickmineault" name="twitter:site"/>
<meta content="The Good Research Code Handbook" name="twitter:title"/>
<meta content="This handbook is for grad students, postdocs and PIs who do a lot of programming as part of their research. It will teach you, in a practical manner, how to organize your code so that it is easy to understand and works reliably." name="twitter:description"/>
<meta content="https://goodresearch.dev/_images/unicorn.png" name="twitter:image"/>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-3Q6LDVNS0X"></script>
<script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){ dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'G-3Q6LDVNS0X');
    </script>
</meta></link></link></link></link></link></link></link></link></link></head>
<body data-offset="80" data-spy="scroll" data-target="#bd-toc-nav">
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
<div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
<img alt="logo" class="logo" src="_static/logo.png"/>
<h1 class="site-logo" id="site-title">Machine Learning as Tool and Theory in Computational Neuroscience</h1>
</a>
</div><form action="search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="index.html">
</a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Intro
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="intro.html">
   Introduction
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="intro1.html">
   Neurophysiology practice and the complexity of sensory cortex
  </a>
</li>
<li class="toctree-l1 current active">
<a class="current reference internal" href="#">
   Learning and its consequences
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="structure.html">
   Structure of this dissertation
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Chapters
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="chap1.html">
   Hue tuning curves in V4 change with visual context
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chap2.html">
   Modern machine learning as benchmark for encoding models
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chap3.html">
   The Four Roles of Supervised Machine Learning in Systems Neuroscience
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chap4.html">
   A role for cortical interneurons as adversarial discriminators
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chap5.html">
   Measuring and regularizing networks in function space
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chap6.html">
   Efficient neural codes naturally emerge through gradient descent learning
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Conclusions
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="conclusions.html">
   Conclusions
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="acknowledgements.html">
   Acknowledgements
  </a>
</li>
</ul>
</div>
</nav> <!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
<div class="topbar container-xl fixed-top">
<div class="topbar-contents row">
<div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
<div class="col pl-md-4 topbar-main">
<button aria-controls="site-navigation" aria-expanded="true" aria-label="Toggle navigation" class="navbar-toggler ml-0" data-placement="left" data-target=".site-navigation" data-toggle="tooltip" id="navbar-toggler" title="Toggle navigation" type="button">
<i class="fas fa-bars"></i>
<i class="fas fa-arrow-left"></i>
<i class="fas fa-arrow-up"></i>
</button>
<div class="dropdown-buttons-trigger">
<button aria-label="Download this page" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fas fa-download"></i></button>
<div class="dropdown-buttons">
<!-- ipynb file if we had a myst markdown file -->
<!-- Download raw file -->
<a class="dropdown-buttons" href="_sources/intro2.md"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Download source file" type="button">.md</button></a>
<!-- Download PDF via print -->
<button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" id="download-print" onclick="window.print()" title="Print to PDF" type="button">.pdf</button>
</div>
</div>
<!-- Source interaction buttons -->
<div class="dropdown-buttons-trigger">
<button aria-label="Connect with source repository" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fab fa-github"></i></button>
<div class="dropdown-buttons sourcebuttons">
<a class="repository-button" href="https://github.com/aribenjamin/machine-learning-for-neuroscience.github.io"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Source repository" type="button"><i class="fab fa-github"></i>repository</button></a>
<a class="issues-button" href="https://github.com/aribenjamin/machine-learning-for-neuroscience.github.io/issues/new?title=Issue%20on%20page%20%2Fintro2.html&amp;body=Your%20issue%20content%20here."><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Open an issue" type="button"><i class="fas fa-lightbulb"></i>open issue</button></a>
<a class="edit-button" href="https://github.com/aribenjamin/machine-learning-for-neuroscience.github.io/edit/main/./intro2.md"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Edit this page" type="button"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
</div>
</div>
<!-- Full screen (wrap in <a> to have style consistency -->
<a class="full-screen-button"><button aria-label="Fullscreen mode" class="btn btn-secondary topbarbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode" type="button"><i class="fas fa-expand"></i></button></a>
<!-- Launch buttons -->
</div>
<!-- Table of contents -->
<div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
            </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#a-learning-objective-representation-learning">
   A learning objective: representation learning
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#a-learning-algorithm-improving-upon-gradient-descent">
   A learning algorithm: improving upon gradient descent
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#the-sensory-consequences-of-learning-algorithms">
   The sensory consequences of learning algorithms
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary-and-outlook">
   Summary and outlook
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#references">
   References
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="row" id="main-content">
<div class="col-12 col-md-9 pl-md-3 pr-md-0">
<div>
<div class="section" id="learning-and-its-consequences">
<h1>Learning and its consequences<a class="headerlink" href="#learning-and-its-consequences" title="Permalink to this headline">¶</a></h1>
<p>Complex systems can emerge from simple rules. Recently, some in computational neuroscience have argued to shift the focus away from the computations performed in the brain and towards how they are learned (Lillicrap &amp; Kording, 2019; Richards et al., 2019). Proponents of this shift often argue that in ANNs, the emergent computation is much more difficult to understand than the factors set by the practitioner – the architecture, the learning objective, and the learning algorithm. The same may be true of brains. Rather than deconstructing the computation of networks, this effort seeks to understand how they learn and to what ends. It is a ‘deep learning framework’ for neuroscience.</p>
<p>A deep learning framework is not an effort to map the components of modern deep learning systems onto the brain. Rather, it means adopting a computational language developed by machine learning and statistical learning theory – disciplines that are concerned with describing learning and learnability in the abstract. This rich language has enormous potential to help understand how brains learn and how this shapes the meaning of neural activity.</p>
<p>In Section 2 of this dissertation, I embrace this approach to understanding the brain in the course of three chapters. These projects each use deep learning models and theory in order to reason about learning in the brain. Each takes up one of the following questions: what are potential learning objectives for sensory cortex? What are potential learning algorithms? And what are the sensory consequences for having learned with such algorithms?</p>
<div class="section" id="a-learning-objective-representation-learning">
<h2>A learning objective: representation learning<a class="headerlink" href="#a-learning-objective-representation-learning" title="Permalink to this headline">¶</a></h2>
<p>One of the core concepts in a learning framework is the objective or goal of learning. This is a teleological interpretation of neuronal plasticity. Much of this dissertation focuses on perception. What is the objective of plasticity in sensory cortex?</p>
<p>In Chapter 5, I examine the hypothesis that the sensory cortex aims to form internal representations of the external world. This objective of representation learning is central concept in neuroscience (though not without critique (Baker, Lansdell, &amp; Kording, 2021; Brette, 2019)). As commonly defined, representations are transformations of sensory data into forms that are more useful to an organism. Good representations might highlight the true organizing principles of the world (Kersten, Mamassian, &amp; Yuille, 2004) or encode information as best as possible while using minimal energy (Barlow, 1961). In this broad frame, the goal of sensory learning is to form useful representations.</p>
<p>Representations are also key concept in machine learning. There, many works have attempted to formalize how to produce useful representations. One popular approach imagines that good sensory systems first create a model of the sensory world, and then infer the representations in that model that explain sensory data (Yuille &amp; Kersten, 2006). Perception might be like a video-game rendering engine with representations of the lighting, materials, and objects that best explain a visual scene; a ‘simulation in the mind’ (Ullman, Spelke, Battaglia, &amp; Tenenbaum, 2017). Many different types of models are possible, making this a general and flexible way to describe representations.</p>
<p>What would be required if the brain learns representations in this way? In this Chapter, I aim to characterize the specific problems that this introduces for neural circuits. I then develop theories about possible solutions that may be taken by sensory cortex. These theories draw from machine learning techniques for representation learning, but are adapted so as to serve as biological hypotheses. The goal is to evaluate whether this class of objectives is a candidate for a description of the objective of sensory learning.</p>
</div>
<div class="section" id="a-learning-algorithm-improving-upon-gradient-descent">
<h2>A learning algorithm: improving upon gradient descent<a class="headerlink" href="#a-learning-algorithm-improving-upon-gradient-descent" title="Permalink to this headline">¶</a></h2>
<p>A learning algorithm is a set of rules prescribing how a system ought to change over time. A deep learning framework for neuroscience aims to build a computational understanding of the brain’s learning algorithms, abstracted from the level of synaptic plasticity and its cellular implementation. Because this effort is in its infancy, a crucial first step is to identify and understand the candidate algorithms.</p>
<p>Chapter 6 represents a foray into the fields of deep learning optimization and deep learning theory. These fields have identified algorithms that work well on deep learning systems, and then sought to understand why they work. The baseline algorithm is gradient descent, in which all parameters change proportional to their effect upon the output. Yet in deep learning, almost all papers now use different algorithms that, in practice, produce better networks with less training data. This chapter discusses a theoretical perspective on algorithms that improve upon gradient descent, and then uses this to derive a new algorithm for learning.</p>
<p>Of all that machine learning has to offer a neuroscience of learning, perhaps the most important is simply a recognition of how difficult and unlikely learning really is. Like scientists pulling general knowledge from limited experiments, learning systems must pull generalities from limited experience. This requires making assumptions (David H. Wolpert &amp; Macready, 1997). In deep learning systems, the assumptions come as much from the learning algorithm as the constraints of the system itself (Zhang, Bengio, Hardt, Recht, &amp; Vinyals, 2021). Somehow, on certain problems, learning algorithms ‘choose’ to learn knowledge that generalizes well. The network, algorithm, and data conspire together for effective learning. Since the brain, too, has a staggering amount of plastic parameters, the theories that describe why ANNs generalize are likely to be useful for describing why we learn so effectively, too.</p>
</div>
<div class="section" id="the-sensory-consequences-of-learning-algorithms">
<h2>The sensory consequences of learning algorithms<a class="headerlink" href="#the-sensory-consequences-of-learning-algorithms" title="Permalink to this headline">¶</a></h2>
<p>A deep learning framework does not require abandoning a study of responses for a study of objectives and algorithms. Understanding learning may be the best ways to gain insight about responses, as well. This requires that bridges be built between neuroscience and deep learning theory.</p>
<p>An important lesson of deep learning is that the learning algorithm leaves permanent traces upon the network and the function it implements. The algorithm is not an incidental and ultimately ignorable process. The traces left by are learning are in fact so important that useful learning in large neural networks is not possible without them (Zhang et al., 2021). These traces are the bias of the learning algorithm, which are effectively assumptions about what is important to learn. As mentioned in the previous section, such assumptions are necessary for learning. Neural network representations thus must carry the imprint of algorithms that generalize well from limited data.</p>
<p>This perspective is new to neuroscience. Usually, when explaining why neural representations take one form or another, neuroscience reaches to normative explanations and describes how the adult representation is optimal in some sense. A hypothesis of this flavor is that sensory representations minimize the number of spikes required to encode external information because of evolutionary pressure on energy usage (Bruno A. Olshausen &amp; Field, 1996; Rao &amp; Ballard, 1999). Though pressures like this certainly exist, there also exists an evolutionary pressure to learn effectively as an infant. Explaining adult representations via their emergence from effective learning algorithms introduces a new type of explanation, this time referencing machine learning theory.</p>
<p>In Chapter 7, I show how such ideas can explain a set of findings in psychophysics and neurophysiology about sensory representations. In humans and other animals, sensory systems tend to better encode the features of the world that are more common, especially for low-level features like orientation and color (Wei &amp; Stocker, 2017). In information theory, such a strategy represents an efficient code – a code that makes best use of a channel with limited capacity. In a collaboration with the lab of Alan Stocker, we use artificial neural networks as model systems to demonstrate that gradient descent learning naturally results in efficient codes, as well.</p>
<p>Learning in the brain is unlikely to be gradient descent, precisely, but a similar principle is likely to be in play. As the algorithms of sensory learning come into focus for neuroscience, it will be interesting to describe how these shape what our brains choose to learn from experience.</p>
</div>
<div class="section" id="summary-and-outlook">
<h2>Summary and outlook<a class="headerlink" href="#summary-and-outlook" title="Permalink to this headline">¶</a></h2>
<p>To understand neural computation, a learning framework looks to its source. Yet, like computation, learning can be understood at many levels. A deep learning or machine learning framework for neuroscience aims for a high-level, normative understanding in terms able to be abstracted from the brain’s implementation.</p>
<p>The projects in this dissertation endeavor to use modern theories of machine learning to advance neuroscience. Along the way they engage with a number of leading theories of sensory processing, asking, always, how might these be learned? To find answers, I pull ideas from multiple subfields of artificial intelligence, from optimization to generative adversarial networks to deep learning theory. These machine learning perspectives offer new types of explanations and predictions for neuroscience.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p>Aljadeff, J., Lansdell, B. J., Fairhall, A. L., &amp; Kleinfeld, D. (2016). Analysis of neuronal spike trains, deconstructed. Neuron, 91(2), 221-259.</p>
<p>Baker, B., Lansdell, B., &amp; Kording, K. (2021). A philosophical understanding of representation for neuroscience. arXiv preprint arXiv:2102.06592.</p>
<p>Barlow, H. B. (1961). Possible principles underlying the transformation of sensory messages. Sensory communication, 1(01).
Brette, R. (2019). Is coding a relevant metaphor for the brain? Behavioral and brain sciences, 42.</p>
<p>Cadena, S. A., Denfield, G. H., Walker, E. Y., Gatys, L. A., Tolias, A. S., Bethge, M., &amp; Ecker, A. S. (2019). Deep convolutional models improve predictions of macaque V1 responses to natural images. PLoS Computational Biology, 15(4), e1006897.</p>
<p>Goh, G., Cammarata, N., Voss, C., Carter, S., Petrov, M., Schubert, L., … Olah, C. (2021). Multimodal neurons in artificial neural networks. Distill, 6(3), e30.</p>
<p>Jonas, E., &amp; Kording, K. P. (2017). Could a neuroscientist understand a microprocessor? PLoS Computational Biology, 13(1), e1005268.</p>
<p>Kersten, D., Mamassian, P., &amp; Yuille, A. (2004). Object perception as Bayesian inference. Annu. Rev. Psychol., 55, 271-304.
Keten, S., Xu, Z., Ihle, B., &amp; Buehler, M. J. (2010). Nanoconfinement controls stiffness, strength and mechanical toughness of β-sheet crystals in silk. Nature materials, 9(4), 359-367.</p>
<p>Lillicrap, T. P., &amp; Kording, K. P. (2019). What does it mean to understand a neural network? arXiv preprint arXiv:1907.06374.</p>
<p>Marblestone, A. H., Wayne, G., &amp; Kording, K. P. (2016). Toward an integration of deep learning and neuroscience. Frontiers in Computational Neuroscience, 94.</p>
<p>Olah, C., Mordvintsev, A., &amp; Schubert, L. (2017). Feature visualization. Distill, 2(11), e7.</p>
<p>Olshausen, B. A., &amp; Field, D. J. (1996). Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature, 381(6583), 607-609.</p>
<p>Olshausen, B. A., &amp; Field, D. J. (2005). How close are we to understanding V1? Neural computation, 17(8), 1665-1699.</p>
<p>Olshausen, B. A., &amp; Field, D. J. (2006). What is the other 85 percent of V1 doing. L. van Hemmen, &amp; T. Sejnowski (Eds.), 23, 182-211.</p>
<p>Rao, R. P. N., &amp; Ballard, D. H. (1999). Hierarchical Predictive Coding Model Hierarchical Predictive Coding of Natural Images. Nature Neuroscience, 2(1), 79-87.</p>
<p>Richards, B. A., Lillicrap, T. P., Beaudoin, P., Bengio, Y., Bogacz, R., Christensen, A., … Ganguli, S. (2019). A deep learning framework for neuroscience. Nature Neuroscience, 22(11), 1761-1770.</p>
<p>Rieke, F., Warland, D., Van Steveninck, R. d. R., &amp; Bialek, W. (1999). Spikes: exploring the neural code: MIT press.</p>
<p>Rust, N. C., &amp; Movshon, J. A. (2005). In praise of artifice. Nature Neuroscience, 8(12), 1647-1650.</p>
<p>Ullman, T. D., Spelke, E., Battaglia, P., &amp; Tenenbaum, J. B. (2017). Mind games: Game engines as an architecture for intuitive physics. Trends in cognitive sciences, 21(9), 649-665.</p>
<p>Wei, X. X., &amp; Stocker, A. A. (2017). Lawful relation between perceptual bias and discriminability. Proceedings of the National Academy of Sciences of the United States of America, 114(38), 10244-10249. doi:10.1073/pnas.1619153114</p>
<p>Wolpert, D. H., &amp; Macready, W. G. (1997). No free lunch theorems for optimization. IEEE transactions on evolutionary computation, 1(1), 67-82.</p>
<p>Yuille, A., &amp; Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends in cognitive sciences, 10(7), 301-308. doi:10.1016/j.tics.2006.05.002</p>
<p>Zhang, C., Bengio, S., Hardt, M., Recht, B., &amp; Vinyals, O. (2021). Understanding deep learning (still) requires rethinking generalization. Communications of the ACM, 64(3), 107-115.</p>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "aribenjamin/machine-learning-for-neuroscience.github.io",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
<div class="prev-next-bottom">
<div id="prev">
<a class="left-prev" href="intro1.html" title="previous page">
<i class="prevnext-label fas fa-angle-left"></i>
<div class="prevnext-info">
<p class="prevnext-label">previous</p>
<p class="prevnext-title">Neurophysiology practice and the complexity of sensory cortex</p>
</div>
</a>
</div>
<div id="next">
<a class="right-next" href="structure.html" title="next page">
<div class="prevnext-info">
<p class="prevnext-label">next</p>
<p class="prevnext-title">Structure of this dissertation</p>
</div>
<i class="prevnext-label fas fa-angle-right"></i>
</a>
</div>
</div>
</div>
</div>
<footer class="footer">
<div class="container">
<p>
        
          By <a href="https://ari-benjamin.com">Ari Benjamin</a> <a href="https://twitter.com/aribenjamin"> This is an online version of my PhD dissertation, submitted to UPenn in 2022. <img alt="Twitter" height="24" src="_images/twitter.svg" style="width:24px" width="24"/></a><br/>
        
            © Copyright 2021–2022.<br/>
<div class="extra_footer">
            Licensed under <a href="https://github.com/aribenjamin/machine-learning-for-neuroscience.github.io/blob/main/LICENSE">CC-BY 4.0</a> [<a href="https://github.com/aribenjamin/machine-learning-for-neuroscience.github.io">source</a>].<br/><a href="https://github.com/aribenjamin/machine-learning-for-neuroscience.github.io/issues">Report issue</a>.
          </div>
</p>
</div>
</footer>
<!-- Place this tag in your head or just before your close body tag. -->
<script async="" defer="" src="https://buttons.github.io/buttons.js"></script>
</main>
</div>
</div>
<script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'jd98', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>
</body>
</html>